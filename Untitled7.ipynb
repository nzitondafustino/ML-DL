{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"qQxIGBz__mMS"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device:  cpu\n","Data fetching....\n","Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n","train.npy.zip: Skipping, found more recently modified local copy (use --force to force download)\n","sample.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n","dev.npy.zip: Skipping, found more recently modified local copy (use --force to force download)\n","dev_labels.npy.zip: Skipping, found more recently modified local copy (use --force to force download)\n","test.npy.zip: Skipping, found more recently modified local copy (use --force to force download)\n","train_labels.npy.zip: Skipping, found more recently modified local copy (use --force to force download)\n","Archive:  /content/dev.npy.zip\n","replace dev.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Device: \",device)\n","print(\"Data fetching....\")\n","import os\n","kaggle_data={\"username\":\"kleber0\",\"key\":\"31c7efab560bf0ae89adce7fa28372ed\"}\n","os.environ['KAGGLE_USERNAME']=kaggle_data[\"username\"]\n","os.environ['KAGGLE_KEY']=kaggle_data[\"key\"]\n","import kaggle\n","!kaggle competitions download -c idl-fall2021-hw1p2\n","!unzip /content/dev.npy.zip\n","!unzip /content/dev_labels.npy.zip\n","!unzip /content/train.npy.zip\n","!unzip /content/train_labels.npy.zip\n","!unzip /content/test.npy.zip\n","train_data = np.load('/content/train.npy', allow_pickle = True)\n","train_labels = np.load('/content/train_labels.npy', allow_pickle = True)\n","val_data = np.load('/content/dev.npy', allow_pickle = True)\n","val_labels = np.load('/content/dev_labels.npy', allow_pickle = True)\n","#test_data = np.load('efs/test.npy', allow_pickle = True)\n","\n","output_size = 71\n","hidden_size = 2048\n","learning_rate = 0.001\n","epochs = 20\n","batch_size = 32\n","context = 20\n","pad_val = 20\n","input_size = (1 + 2*context)*40\n","\n","class myDataset(Dataset):\n","    \n","    def __init__(self, X, Y=None, pad_val=5, context=5, is_test = False):\n","        \n","        ### Add data and label to self (1-2 lines)\n","        self.X = X\n","        self.Y = Y\n","        self.is_test = is_test\n","        ### Define data index mapping (4-6 lines)\n","        index_map_x = []\n","        for i, x in enumerate(X):\n","            for j, xx in enumerate(x):\n","                index_pair_x = (i, j)\n","                index_map_x.append(index_pair_x)\n","                \n","        ### Define label index mapping (4-6 lines)\n","        if(not is_test):\n","            index_map_y = []\n","            for i, y in enumerate(Y):\n","                for j, yy in enumerate(y):\n","                    index_pair_y = (i, j)\n","                    index_map_y.append(index_pair_y)\n","\n","            ### Assert the data index mapping and label index mapping are the same (1 line)\n","\n","            assert(set(index_map_x) == set(index_map_y))\n","\n","        ### Assign data index mapping to self (1 line)\n","        self.index_map_X = index_map_x\n","        \n","        ### Add length to self (1 line)\n","        self.length = len(self.index_map_X)\n","        \n","        ### Add context and offset to self (1-2 line)\n","        self.pad_val = pad_val\n","        self.context = context\n","        \n","        ### Zero pad data as-needed for context size = 1 (1-2 lines)\n","        for i, x in enumerate(self.X):\n","            self.X[i] = np.pad(x,((pad_val, pad_val), (0, 0)),'constant',constant_values=0)\n","        \n","    def __len__(self):\n","        \n","        ### Return length (1 line)\n","        return self.length\n","    \n","    def __getitem__(self, index):\n","        \n","        ### Get index pair from index map (1-2 lines)\n","        i, j= self.index_map_X[index]\n","        \n","        ### Calculate starting timestep using offset and context (1 line)\n","        start_j = j + self.pad_val - self.context\n","        \n","        ## Calculate ending timestep using offset and context (1 line)\n","        end_j = j + self.pad_val + self.context + 1\n","        \n","        ### Get data at index pair with context (1 line)\n","        x = self.X[i][start_j:end_j,:]\n","        x = x.flatten()\n","        ### Get label at index pair (1 line)\n","        if(not self.is_test):\n","            y = self.Y[i][j]\n","            ### Return data at index pair with context and label at index pair (1 line)\n","            return x, y\n","        else:\n","            return x\n","    \n","    def my_collate_fn(batch):\n","        \n","        batch_x = [x for x,y in batch]\n","        batch_x = torch.as_tensor(batch_x)\n","        if(not self.is_test):\n","            batch_y = [y for x,y in batch]        \n","            batch_y = torch.as_tensor(batch_y)\n","            return batch_x, batch_y\n","        else:\n","            return batch_x\n","    \n","class Model(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super().__init__()\n","        self.l1 = nn.Linear(input_size, hidden_size)\n","        self.l2 = nn.Linear(hidden_size,int(hidden_size/2))\n","        self.l3 = nn.Linear(int(hidden_size/2),int(hidden_size/4))\n","        self.l4 = nn.Linear(int(hidden_size/4),output_size)\n","    \n","    def forward(self,x):\n","        out = self.l1(x)\n","        out = F.relu(out)\n","        out = self.l2(out)\n","        out = F.relu(out)\n","        out = self.l3(out)\n","        out = F.relu(out)\n","        out = self.l4(out)\n","        return out\n","\n","def init_weights(model):\n","    if isinstance(model, nn.Linear):\n","        torch.nn.init.xavier_uniform_(model.weight)\n","        model.bias.data.fill_(0.01)\n","print(\"Model init....\")\n","criterion = nn.CrossEntropyLoss().to(device)\n","model = Model(input_size,hidden_size,output_size)\n","model.apply(init_weights)\n","model.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n","print(\"DataLoading.....\")\n","train_dataset = myDataset(train_data, train_labels, pad_val, context)\n","val_dataset = myDataset(val_data, val_labels, pad_val, context)\n","#test_dataset = myDataset(test_data,None,pad_val,context,is_test=True)\n","train_loader = DataLoader(dataset = train_dataset ,batch_size = batch_size, shuffle = True, collate_fn = my_collate_fn)\n","val_loader = DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle = False, collate_fn = my_collate_fn)\n","#test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)\n","\n","PATH='efs/model.pt'\n","print(\"Training......\")\n","train_steps = len(train_loader)\n","val_steps = len(val_loader)\n","val_loss_min = np.Inf\n","\n","for epoch in range(epochs):\n","    running_loss = 0\n","    model.train()\n","    print(\"Training......\")\n","\n","    for i, (data, labels) in enumerate(train_loader):\n","#         print(data.shape)\n","        \n","        data = data.to(device)\n","#         print(data.dtype)\n","#         print(data.shape)\n","        labels = labels.to(device)\n","#         print(labels.shape)\n","        output = model(data.float())\n","        loss = criterion(output, labels.long())\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","        if (i+1) % 2000 == 0:\n","            print(f'epoch {epoch+1} /{epochs}, step {i+1}/{train_steps}, train_loss = {loss.item()}')\n","          \n","    avg_train_loss = running_loss/train_steps\n","    running_loss = 0\n","    running_val_loss = []\n","    model.eval()\n","    print(\"Validation.......\")\n","    for j, (val_data,val_labels) in enumerate(val_loader):\n","        val_data = val_data.to(device)\n","        val_labels = val_labels.to(device) \n","        val_output = model(val_data.float())\n","        val_loss = criterion(val_output, val_labels.long())\n","        running_val_loss += val_loss\n","        if (j+1) % 2000 == 0:\n","            print(f'epoch {epoch+1} /{epochs}, step {j+1}/{val_steps}, val_loss = {val_loss.item()}')\n","        \n","    avg_val_loss = running_val_loss/val_steps\n","    print(\"\\n=============================\\n\")\n","    print(\"Average loss, train: \",avg_train_loss,\" | val: \",avg_val_loss)\n","    print(\"\\n=============================\\n\")\n","    checkpoint = {\n","        \"epoch\":epoch+1,\n","        \"model_state\":model.state_dict(),\n","        \"optim_state\":optimizer.state_dict(),\n","        \"val_loss\":avg_val_loss\n","    }\n","    if avg_val_loss \u003c val_loss_min:\n","        print(\"Val-loss decreased: \",avg_val_loss)\n","        val_loss_min = avg_val_loss\n","        print(\"Saving model........\")\n","        torch.save(checkpoint,PATH)\n","        \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1633538452614,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"},"user_tz":-120},"id":"vfs17Bwr_zbc","outputId":"4bd24471-64d8-4568-b578-bc59d81c5e22"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"]}],"source":["ls/content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mx9MDlzDAuM2"},"outputs":[],"source":[""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO1T23uD+QFrWUt3Ab+5o4C","machine_shape":"hm","name":"Untitled7.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}