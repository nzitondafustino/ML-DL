{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"training.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"oxiZ42B4SwQ-","executionInfo":{"status":"ok","timestamp":1638098229694,"user_tz":-120,"elapsed":439,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["%matplotlib inline\n","\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import time\n","import os\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader\n","from handout.hw4.tests import test_prediction, test_generation"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5znxQhLSwRC","executionInfo":{"status":"ok","timestamp":1638098232718,"user_tz":-120,"elapsed":510,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["# load all that we need\n","\n","dataset = np.load('/content/handout/dataset/wiki.train.npy', allow_pickle=True)\n","devset = np.load('/content/handout/dataset/wiki.valid.npy', allow_pickle=True)\n","fixtures_pred = np.load('/content/handout/fixtures/prediction.npz')  # dev\n","fixtures_gen = np.load('/content/handout/fixtures/generation.npy')  # dev\n","fixtures_pred_test = np.load('/content/handout/fixtures/prediction_test.npz')  # test\n","fixtures_gen_test = np.load('/content/handout/fixtures/generation_test.npy')  # test\n","vocab = np.load('/content/handout/dataset/vocab.npy')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"OZNrJ8XvSwRF","executionInfo":{"status":"ok","timestamp":1638098235507,"user_tz":-120,"elapsed":5,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["# data loader\n","class LanguageModelDataLoader(DataLoader):\n","    \"\"\"\n","        TODO: Define data loader logic here\n","    \"\"\"\n","    def __init__(self, dataset, batch_size, shuffle=True,seq_len = 20):\n","        super().__init__(dataset, batch_size=batch_size, shuffle= shuffle)\n","        self.shuffle = shuffle\n","        self.seq_len = seq_len\n","        # raise NotImplemented\n","    def __iter__(self):\n","        # concatenate your articles and build into batches\n","        batches = np.hstack(self.dataset)\n","        # print(len(batches))\n","        r = int(np.floor(len(batches)/self.seq_len))\n","        if r == len(batches)/self.seq_len:\n","            indeces = np.arange(r)\n","        else:\n","            indeces = np.arange(r+1)\n","        if self.shuffle == True:\n","            np.random.shuffle(indeces)\n","        \n","        for i in range(int(np.ceil(indeces.shape[0]/self.batch_size))):\n","            \n","            startx = indeces[i*self.batch_size:i*self.batch_size+self.batch_size]\n","            starty = indeces[i*self.batch_size:i*self.batch_size+self.batch_size] + 1\n","            x = []\n","            y = []\n","            for j in range(self.seq_len):\n","                \n","                x.append(batches[startx+j])\n","                y.append(batches[starty+j])\n","                \n","            x = np.array(x)\n","            y = np.array(y)\n","            \n","            b_x = [x[:,i] for i in range(x.shape[1])]\n","            b_y = [y[:,i] for i in range(y.shape[1])]\n","            \n","            x = torch.LongTensor(b_x)\n","            y = torch.LongTensor(b_y)\n","            \n","            yield x,y\n","        "],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"mVMWqgHJLxTQ","executionInfo":{"status":"ok","timestamp":1638098237626,"user_tz":-120,"elapsed":4,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["\n","# loader = LanguageModelDataLoader(dataset, batch_size = 32,shuffle=True,seq_len = 40)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"pum_Gd0rLxTS","executionInfo":{"status":"ok","timestamp":1638098239420,"user_tz":-120,"elapsed":11,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["# for x,y in loader:\n","#     print(x.shape)\n","#     print(y.shape)\n","#     # break\n","    \n","# \"\"\"\n","# I eat a - eat a banana\n","# eat a banana - a banana and \n","# a banana and - banana and apple\n","# banana and apple - and apple everyday\n","# and apple everyday - apple everyday including\n","# apple everyday including - everyday including today\n","# everyday including today - including today.\n","# \"\"\"\n","\n","\n","\n","# I eat a banana and apple everyday including today.\n","# vocab[x[0]],vocab[y[0]]"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zt-7YsTYSwRI","executionInfo":{"status":"ok","timestamp":1638099582682,"user_tz":-120,"elapsed":468,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["\n","# model\n","\n","class LanguageModel(nn.Module):\n","    \"\"\"\n","        TODO: Define your model here\n","    \"\"\"\n","    def __init__(self, vocab_size,hidden_size=1150):\n","        super(LanguageModel, self).__init__()\n","        \n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(vocab_size,400)\n","        self.embedDropout = nn.Dropout(0.4)\n","               \n","        self. lstm = nn.LSTM(input_size=400,hidden_size=hidden_size,num_layers=2 ,batch_first=True, dropout=0.3)\n","        self.dropout = nn.Dropout(0.4)\n","        self.fc = nn.Linear(hidden_size,vocab_size)\n","        # raise NotImplemented\n","\n","\n","    def forward(self, x):\n","        # Feel free to add extra arguments to forward (like an argument to pass in the hiddens)\n","        # raise NotImplemented\n","        x = self.embedding(x)\n","        x = self.embedDropout(x)\n","        x,hiddens = self. lstm(x)\n","        x = self.dropout(x)\n","        x = self.fc(x.reshape(-1, self.hidden_size))\n","        return x\n"],"execution_count":92,"outputs":[]},{"cell_type":"code","metadata":{"id":"hqt0Lg_0LxTV","executionInfo":{"status":"ok","timestamp":1638099584209,"user_tz":-120,"elapsed":6,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["# x = torch.randint(0,vocab.shape[0],(32,10))\n","# model = LanguageModel(vocab.shape[0])"],"execution_count":93,"outputs":[]},{"cell_type":"code","metadata":{"id":"kIvZOIfjSwRK","executionInfo":{"status":"ok","timestamp":1638099586156,"user_tz":-120,"elapsed":5,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["\n","# model trainer\n","\n","class LanguageModelTrainer:\n","    def __init__(self, model, loader, max_epochs=1, run_id='exp'):\n","        \"\"\"\n","            Use this class to train your model\n","        \"\"\"\n","        # feel free to add any other parameters here\n","        self.model = model\n","        self.loader = loader\n","        self.train_losses = []\n","        self.val_losses = []\n","        self.predictions = []\n","        self.predictions_test = []\n","        self.generated_logits = []\n","        self.generated = []\n","        self.generated_logits_test = []\n","        self.generated_test = []\n","        self.epochs = 0\n","        self.max_epochs = max_epochs\n","        self.run_id = run_id\n","        \n","        # TODO: Define your optimizer and criterion here\n","        self.optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","        self.criterion = nn.CrossEntropyLoss()\n","\n","    def train(self):\n","        self.model.train() # set to training mode\n","        epoch_loss = 0\n","        num_batches = 0\n","        for batch_num, (inputs, targets) in enumerate(self.loader):\n","            epoch_loss += self.train_batch(inputs, targets)\n","        epoch_loss = epoch_loss / (batch_num + 1)\n","        self.epochs += 1\n","        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n","                      % (self.epochs + 1, self.max_epochs, epoch_loss))\n","        self.train_losses.append(epoch_loss)\n","\n","    def train_batch(self, inputs, targets):\n","        \"\"\" \n","            TODO: Define code for training a single batch of inputs\n","        \n","        \"\"\"\n","        inputs = inputs\n","        inputs = targets\n","        self.optimizer.zero_grad()\n","        out = self.model(targets)\n","        loss = self.criterion(out,targets.reshape(-1))\n","        loss.backward()\n","        self.optimizer.step()\n","        return loss\n","        # raise NotImplemented\n","    \n","    def test(self):\n","        # don't change these\n","        self.model.eval() # set to eval mode\n","        predictions = TestLanguageModel.prediction(fixtures_pred['inp'], self.model) # get predictions\n","        self.predictions.append(predictions)\n","        generated_logits = TestLanguageModel.generation(fixtures_gen, 10, self.model) # generated predictions for 10 words\n","        generated_logits_test = TestLanguageModel.generation(fixtures_gen_test, 10, self.model)\n","        nll = test_prediction(predictions, fixtures_pred['out'])\n","        generated = test_generation(fixtures_gen, generated_logits, vocab)\n","        generated_test = test_generation(fixtures_gen_test, generated_logits_test, vocab)\n","        self.val_losses.append(nll)\n","        \n","        self.generated.append(generated)\n","        self.generated_test.append(generated_test)\n","        self.generated_logits.append(generated_logits)\n","        self.generated_logits_test.append(generated_logits_test)\n","        \n","        # generate predictions for test data\n","        predictions_test = TestLanguageModel.prediction(fixtures_pred_test['inp'], self.model) # get predictions\n","        self.predictions_test.append(predictions_test)\n","            \n","        print('[VAL]  Epoch [%d/%d]   Loss: %.4f'\n","                      % (self.epochs + 1, self.max_epochs, nll))\n","        return nll\n","\n","    def save(self):\n","        # don't change these\n","        model_path = os.path.join('experiments', self.run_id, 'model-{}.pkl'.format(self.epochs))\n","        torch.save({'state_dict': self.model.state_dict()},\n","            model_path)\n","        np.save(os.path.join('experiments', self.run_id, 'predictions-{}.npy'.format(self.epochs)), self.predictions[-1])\n","        np.save(os.path.join('experiments', self.run_id, 'predictions-test-{}.npy'.format(self.epochs)), self.predictions_test[-1])\n","        np.save(os.path.join('experiments', self.run_id, 'generated_logits-{}.npy'.format(self.epochs)), self.generated_logits[-1])\n","        np.save(os.path.join('experiments', self.run_id, 'generated_logits-test-{}.npy'.format(self.epochs)), self.generated_logits_test[-1])\n","        with open(os.path.join('experiments', self.run_id, 'generated-{}.txt'.format(self.epochs)), 'w') as fw:\n","            fw.write(self.generated[-1])\n","        with open(os.path.join('experiments', self.run_id, 'generated-{}-test.txt'.format(self.epochs)), 'w') as fw:\n","            fw.write(self.generated_test[-1])\n"],"execution_count":94,"outputs":[]},{"cell_type":"code","metadata":{"id":"xPI7_kZRSwRN","executionInfo":{"status":"ok","timestamp":1638099588307,"user_tz":-120,"elapsed":5,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["class TestLanguageModel:\n","    def prediction(inp, model):\n","        \"\"\"\n","            TODO: write prediction code here\n","            \n","            :param inp:\n","            :return: a np.ndarray of logits\n","        \"\"\"\n","        raise NotImplemented\n","\n","        \n","    def generation(inp, forward, model):\n","        \"\"\"\n","            TODO: write generation code here\n","\n","            Generate a sequence of words given a starting sequence.\n","            :param inp: Initial sequence of words (batch size, length)\n","            :param forward: number of additional words to generate\n","            :return: generated words (batch size, forward)\n","        \"\"\"        \n","        raise NotImplemented\n","        "],"execution_count":95,"outputs":[]},{"cell_type":"code","metadata":{"id":"TiUrjbEjSwRQ","executionInfo":{"status":"ok","timestamp":1638099590739,"user_tz":-120,"elapsed":6,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["# TODO: define other hyperparameters here\n","\n","NUM_EPOCHS = 10\n","BATCH_SIZE = 32\n"],"execution_count":96,"outputs":[]},{"cell_type":"code","metadata":{"id":"2HCVG5YISwRW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638099592709,"user_tz":-120,"elapsed":7,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"1c8db1da-7544-4831-dce2-5f7c12be5ec7"},"source":["\n","run_id = str(int(time.time()))\n","if not os.path.exists('./experiments'):\n","    os.mkdir('./experiments')\n","os.mkdir('./experiments/%s' % run_id)\n","print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)"],"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving models, predictions, and generated words to ./experiments/1638099581\n"]}]},{"cell_type":"code","metadata":{"id":"DbHH6zXTSwRa","executionInfo":{"status":"ok","timestamp":1638099595479,"user_tz":-120,"elapsed":593,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["model = LanguageModel(len(vocab))\n","loader = LanguageModelDataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n","trainer = LanguageModelTrainer(model=model, loader=loader, max_epochs=NUM_EPOCHS, run_id=run_id)"],"execution_count":98,"outputs":[]},{"cell_type":"code","metadata":{"id":"7D8wTJkBSwRc","colab":{"base_uri":"https://localhost:8080/","height":400},"executionInfo":{"status":"error","timestamp":1638103669010,"user_tz":-120,"elapsed":122836,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"d958498b-28ac-49fe-fbb1-0b29c061fa3f"},"source":["best_nll = 1e30 \n","for epoch in range(NUM_EPOCHS):\n","    trainer.train()\n","    nll = trainer.test()\n","    print(\"Training\")\n","    if nll < best_nll:\n","        best_nll = nll\n","        print(\"Saving model, predictions and generated output for epoch \"+str(epoch)+\" with NLL: \"+ str(best_nll))\n","        trainer.save()\n","    "],"execution_count":99,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-99-1092211f1d69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_nll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-94-9632e76d1443>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mnum_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_num\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-94-9632e76d1443>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# raise NotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"z2FmDqBCSwRf"},"source":["# Don't change these\n","# plot training curves\n","plt.figure()\n","plt.plot(range(1, trainer.epochs + 1), trainer.train_losses, label='Training losses')\n","plt.plot(range(1, trainer.epochs + 1), trainer.val_losses, label='Validation losses')\n","plt.xlabel('Epochs')\n","plt.ylabel('NLL')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ipdbmqaGSwRh"},"source":["# see generated output\n","print (trainer.generated[-1]) # get last generated output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3wqVDLLWMHUP","executionInfo":{"status":"ok","timestamp":1638098223478,"user_tz":-120,"elapsed":791,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["# !unzip /content/handout.zip"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"7LYhEW5zMKZI"},"source":[""],"execution_count":null,"outputs":[]}]}