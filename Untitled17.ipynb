{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled17.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOzNY8AZvZ4RTargWxtP/dX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"gCd_HPrDLNyG","executionInfo":{"status":"ok","timestamp":1637962940014,"user_tz":-120,"elapsed":5170,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["import re\n","import pickle\n","import random\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"0SL0ByPKNbS9","executionInfo":{"status":"ok","timestamp":1637963265285,"user_tz":-120,"elapsed":494,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["# https://drive.google.com/file/d/1PakdWMKYNyC5-2G_CSlLtkBsHezFpMHJ/view?usp=sharing"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uesjRWFDLdjh","executionInfo":{"status":"ok","timestamp":1637963267247,"user_tz":-120,"elapsed":10,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"521ed231-1218-41b5-fbe1-c7d8efaaace7"},"source":["pickle_in = open(\"plots_text.pickle\",\"rb\")\n","movie_plots = pickle.load(pickle_in)\n","\n","# count of movie plot summaries\n","len(movie_plots)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["500"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"79gVbFfOL7Ik","executionInfo":{"status":"ok","timestamp":1637963025698,"user_tz":-120,"elapsed":480,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["# !nvidia-smi"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"D6L_IenaMzjb","executionInfo":{"status":"ok","timestamp":1637963288928,"user_tz":-120,"elapsed":526,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["def create_seq(text, seq_len = 5):\n","    \n","    sequences = []\n","\n","    # if the number of tokens in 'text' is greater than 5\n","    if len(text.split()) > seq_len:\n","        for i in range(seq_len, len(text.split())):\n","            # select sequence of tokens\n","            seq = text.split()[i-seq_len:i+1]\n","            # add to the list\n","            sequences.append(\" \".join(seq))\n","\n","        return sequences\n","\n","    # if the number of tokens in 'text' is less than or equal to 5\n","    else:\n","        return [text]"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zdsIWFiROEyD","executionInfo":{"status":"ok","timestamp":1637963299894,"user_tz":-120,"elapsed":4404,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"004290d1-23be-42d1-8d73-a1d292a88461"},"source":["seqs = [create_seq(i) for i in movie_plots]\n","\n","# merge list-of-lists into a single list\n","seqs = sum(seqs, [])\n","\n","# count of sequences\n","len(seqs)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["154084"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"Xm2Pw79yOGhF","executionInfo":{"status":"ok","timestamp":1637963309778,"user_tz":-120,"elapsed":674,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["x = []\n","y = []\n","\n","for s in seqs:\n","    x.append(\" \".join(s.split()[:-1]))\n","    y.append(\" \".join(s.split()[1:]))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IV-xONMSOJ2C","executionInfo":{"status":"ok","timestamp":1637963350497,"user_tz":-120,"elapsed":713,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"d44c62ca-0356-4a4d-f866-004b3780fb14"},"source":["int2token = {}\n","cnt = 0\n","\n","for w in set(\" \".join(movie_plots).split()):\n","    int2token[cnt] = w\n","    cnt+= 1\n","\n","# create token-to-integer mapping\n","token2int = {t: i for i, t in int2token.items()}\n","\n","token2int[\"the\"], int2token[14271]"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(22009, 'psyched')"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"1V8uOpuwOQZT","executionInfo":{"status":"ok","timestamp":1637963383495,"user_tz":-120,"elapsed":1330,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["def get_integer_seq(seq):\n","    return [token2int[w] for w in seq.split()]\n","\n","# convert text sequences to integer sequences\n","x_int = [get_integer_seq(i) for i in x]\n","y_int = [get_integer_seq(i) for i in y]\n","\n","# convert lists to numpy arrays\n","x_int = np.array(x_int)\n","y_int = np.array(y_int)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"bMdoz4cNOX-x","executionInfo":{"status":"ok","timestamp":1637963392741,"user_tz":-120,"elapsed":517,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["def get_batches(arr_x, arr_y, batch_size):\n","         \n","    # iterate through the arrays\n","    prv = 0\n","    for n in range(batch_size, arr_x.shape[0], batch_size):\n","        x = arr_x[prv:n,:]\n","        y = arr_y[prv:n,:]\n","        prv = n\n","        yield x, y"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"I9-qKFqHRCVZ","executionInfo":{"status":"ok","timestamp":1637964109155,"user_tz":-120,"elapsed":533,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["x,y = next(get_batches(x_int,y_int, 32))"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-PaTHUxOeIg","executionInfo":{"status":"ok","timestamp":1637963412876,"user_tz":-120,"elapsed":469,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["class WordLSTM(nn.Module):\n","    \n","    def __init__(self, n_hidden=256, n_layers=4, drop_prob=0.3, lr=0.001):\n","        super().__init__()\n","\n","        self.drop_prob = drop_prob\n","        self.n_layers = n_layers\n","        self.n_hidden = n_hidden\n","        self.lr = lr\n","        \n","        self.emb_layer = nn.Embedding(16592, 200)\n","\n","        ## define the LSTM\n","        self.lstm = nn.LSTM(200, n_hidden, n_layers, \n","                            dropout=drop_prob, batch_first=True)\n","        \n","        ## define a dropout layer\n","        self.dropout = nn.Dropout(drop_prob)\n","        \n","        ## define the fully-connected layer\n","        self.fc = nn.Linear(n_hidden, 16592)      \n","    \n","    def forward(self, x, hidden):\n","        ''' Forward pass through the network. \n","            These inputs are x, and the hidden/cell state `hidden`. '''\n","\n","        ## pass input through embedding layer\n","        embedded = self.emb_layer(x)     \n","        \n","        ## Get the outputs and the new hidden state from the lstm\n","        lstm_output, hidden = self.lstm(embedded, hidden)\n","        \n","        ## pass through a dropout layer\n","        out = self.dropout(lstm_output)\n","        \n","        #out = out.contiguous().view(-1, self.n_hidden) \n","        out = out.reshape(-1, self.n_hidden) \n","\n","        ## put \"out\" through the fully-connected layer\n","        out = self.fc(out)\n","\n","        # return the final output and the hidden state\n","        return out, hidden\n","    \n","    \n","    def init_hidden(self, batch_size):\n","        ''' initializes hidden state '''\n","        # Create two new tensors with sizes n_layers x batch_size x n_hidden,\n","        # initialized to zero, for hidden state and cell state of LSTM\n","        weight = next(self.parameters()).data\n","\n","        # if GPU is available\n","        if (torch.cuda.is_available()):\n","          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(),\n","                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n","        \n","        # if GPU is not available\n","        else:\n","          hidden = (weight.new(self.n_layers, batch_size, self.n_hidden).zero_(),\n","                    weight.new(self.n_layers, batch_size, self.n_hidden).zero_())\n","        \n","        return hidden"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zmwg4sntOjDf","executionInfo":{"status":"ok","timestamp":1637963435906,"user_tz":-120,"elapsed":450,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"c16db7d4-2687-473c-beab-3a4344e1bfe6"},"source":["net = WordLSTM()\n","\n","# push the model to GPU (avoid it if you are not using the GPU)\n","net.cuda()\n","\n","print(net)"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["WordLSTM(\n","  (emb_layer): Embedding(16592, 200)\n","  (lstm): LSTM(200, 256, num_layers=4, batch_first=True, dropout=0.3)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (fc): Linear(in_features=256, out_features=16592, bias=True)\n",")\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":254},"id":"zQmbMK6aQPUI","executionInfo":{"status":"error","timestamp":1637964176772,"user_tz":-120,"elapsed":467,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"cec7a0cd-8bd3-4e02-c96d-01508006aaef"},"source":[""],"execution_count":28,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-7c9f016ae84b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m hidden = (weight.new(net.n_layers, 32, net.n_hidden).zero_().cuda(),\n\u001b[0m\u001b[1;32m      3\u001b[0m weight.new(net.n_layers, 32, net.n_hidden).zero_().cuda())\n\u001b[1;32m      4\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."]}]},{"cell_type":"code","metadata":{"id":"57iyW-1rOmEh","executionInfo":{"status":"ok","timestamp":1637963759228,"user_tz":-120,"elapsed":534,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["def train(net, epochs=10, batch_size=32, lr=0.001, clip=1, print_every=32):\n","    \n","    # optimizer\n","    opt = torch.optim.Adam(net.parameters(), lr=lr)\n","    \n","    # loss\n","    criterion = nn.CrossEntropyLoss()\n","    \n","    # push model to GPU\n","    net.cuda()\n","    \n","    counter = 0\n","\n","    net.train()\n","\n","    for e in range(epochs):\n","\n","        # initialize hidden state\n","        h = net.init_hidden(batch_size)\n","        \n","        for x, y in get_batches(x_int, y_int, batch_size):\n","            counter+= 1\n","            \n","            # convert numpy arrays to PyTorch arrays\n","            inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n","            \n","            # push tensors to GPU\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","\n","            # detach hidden states\n","            h = tuple([each.data for each in h])\n","\n","            # zero accumulated gradients\n","            net.zero_grad()\n","            \n","            # get the output from the model\n","            output, h = net(inputs, h)\n","            \n","            # calculate the loss and perform backprop\n","            loss = criterion(output, targets.view(-1))\n","\n","            # back-propagate error\n","            loss.backward()\n","\n","            # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n","            nn.utils.clip_grad_norm_(net.parameters(), clip)\n","\n","            # update weigths\n","            opt.step()            \n","            \n","            if counter % print_every == 0:\n","            \n","              print(\"Epoch: {}/{}...\".format(e+1, epochs),\n","                    \"Step: {}...\".format(counter))"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"X6ZVTmngPIXh","executionInfo":{"status":"ok","timestamp":1637963590499,"user_tz":-120,"elapsed":465,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["# predict next token\n","def predict(net, tkn, h=None):\n","         \n","  # tensor inputs\n","  x = np.array([[token2int[tkn]]])\n","  inputs = torch.from_numpy(x)\n","  \n","  # push to GPU\n","  inputs = inputs.cuda()\n","\n","  # detach hidden state from history\n","  h = tuple([each.data for each in h])\n","\n","  # get the output of the model\n","  out, h = net(inputs, h)\n","\n","  # get the token probabilities\n","  p = F.softmax(out, dim=1).data\n","\n","  p = p.cpu()\n","\n","  p = p.numpy()\n","  p = p.reshape(p.shape[1],)\n","\n","  # get indices of top 3 values\n","  top_n_idx = p.argsort()[-3:][::-1]\n","\n","  # randomly select one of the three indices\n","  sampled_token_index = top_n_idx[random.sample([0,1,2],1)[0]]\n","\n","  # return the encoded value of the predicted char and the hidden state\n","  return int2token[sampled_token_index], h\n","\n","\n","# function to generate text\n","def sample(net, size, prime='it is'):\n","        \n","    # push to GPU\n","    net.cuda()\n","    \n","    net.eval()\n","\n","    # batch size is 1\n","    h = net.init_hidden(1)\n","\n","    toks = prime.split()\n","\n","    # predict next token\n","    for t in prime.split():\n","      token, h = predict(net, t, h)\n","    \n","    toks.append(token)\n","\n","    # predict subsequent tokens\n","    for i in range(size-1):\n","        token, h = predict(net, toks[-1], h)\n","        toks.append(token)\n","\n","    return ' '.join(toks)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"2gb3LvUYP44x","executionInfo":{"status":"error","timestamp":1637963784710,"user_tz":-120,"elapsed":603,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"973bb0e7-5456-447e-900c-f1aa211dc740"},"source":["train(net, batch_size = 32, epochs=20, print_every=256)"],"execution_count":23,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-166d0309c249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-93df9a796e32>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, batch_size, lr, clip, print_every)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# push model to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \"\"\"\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# Flattens params (on CUDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                         self.batch_first, bool(self.bidirectional))\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_MAPPING_ERROR"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"m2Pdad6MPOXh","executionInfo":{"status":"error","timestamp":1637963684077,"user_tz":-120,"elapsed":556,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"5111aa50-05fe-4549-fdcc-5dc0d1aba71c"},"source":["train(net, batch_size = 32, epochs=20, print_every=256)"],"execution_count":21,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-166d0309c249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-19-93df9a796e32>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, epochs, batch_size, lr, clip, print_every)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;31m# get the output from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# calculate the loss and perform backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-a47e81a89cdd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m## Get the outputs and the new hidden state from the lstm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlstm_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m## pass through a dropout layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 692\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n","\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR"]}]},{"cell_type":"code","metadata":{"id":"yk5NQdH4PlQC"},"source":[""],"execution_count":null,"outputs":[]}]}