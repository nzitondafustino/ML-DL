{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Test_Enc_Dec_Finetuning.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e8b2e0da756147e198e3bccb28076dbd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cdef73fa64d3475d965ac0f6af413e90","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0e9df41469ff42f28d0d3b8b400775ff","IPY_MODEL_9c11374248d0495c86fd5caceeb38f66","IPY_MODEL_13aa750da3324bd2bb07e1f5832344bb"]}},"cdef73fa64d3475d965ac0f6af413e90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0e9df41469ff42f28d0d3b8b400775ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_563977aaab824bb69e71602dcf27a6c9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a3e5f08e31414b46a0d5b5d596ae4f2e"}},"9c11374248d0495c86fd5caceeb38f66":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a7ee517c11684663b1e1fed381753758","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1001,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1001,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a20f670b08844d579dc3c21fe6e570eb"}},"13aa750da3324bd2bb07e1f5832344bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a45c9fee837a4038853d01a60c728113","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1001/1001 [26:08&lt;00:00,  1.55s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5186af8394114659a4d37bd2a5ec0ecb"}},"563977aaab824bb69e71602dcf27a6c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a3e5f08e31414b46a0d5b5d596ae4f2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7ee517c11684663b1e1fed381753758":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a20f670b08844d579dc3c21fe6e570eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a45c9fee837a4038853d01a60c728113":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5186af8394114659a4d37bd2a5ec0ecb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"B5HNNm5OQSS_"},"source":["import pandas as pd"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qws3OE_2QZMo","executionInfo":{"status":"ok","timestamp":1638618236673,"user_tz":-120,"elapsed":15333,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"37d765ef-4ad0-4c34-b47b-e890152ae721"},"source":["!pip install aitextgen"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting aitextgen\n","  Downloading aitextgen-0.5.2.tar.gz (572 kB)\n","\u001b[K     |████████████████████████████████| 572 kB 8.0 MB/s \n","\u001b[?25hCollecting transformers>=4.5.1\n","  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 53.3 MB/s \n","\u001b[?25hCollecting fire>=0.3.0\n","  Downloading fire-0.4.0.tar.gz (87 kB)\n","\u001b[K     |████████████████████████████████| 87 kB 8.8 MB/s \n","\u001b[?25hCollecting pytorch-lightning>=1.3.1\n","  Downloading pytorch_lightning-1.5.4-py3-none-any.whl (524 kB)\n","\u001b[K     |████████████████████████████████| 524 kB 68.2 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from aitextgen) (1.10.0+cu111)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.0->aitextgen) (1.15.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.3.0->aitextgen) (1.1.0)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (2.7.0)\n","Collecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 66.1 MB/s \n","\u001b[?25hCollecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n","\u001b[K     |████████████████████████████████| 329 kB 37.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (1.19.5)\n","Collecting pyDeprecate==0.3.1\n","  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (4.62.3)\n","Collecting PyYAML>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 72.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (21.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning>=1.3.1->aitextgen) (3.10.0.2)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 71.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 68.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.3.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.42.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.37.0)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.17.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.12.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.8.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (4.8.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.6.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning>=1.3.1->aitextgen) (3.1.1)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 631 kB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 59.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.5.1->aitextgen) (3.4.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 43.6 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 64.3 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 74.5 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (21.2.0)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n","\u001b[K     |████████████████████████████████| 192 kB 74.6 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning>=1.3.1->aitextgen) (2.0.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.5.1->aitextgen) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.5.1->aitextgen) (7.1.2)\n","Building wheels for collected packages: aitextgen, fire, future\n","  Building wheel for aitextgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for aitextgen: filename=aitextgen-0.5.2-py3-none-any.whl size=575905 sha256=53fd6fabca981e9f1e723adb998157445f1d187f7f7db1ff94b3fa73e44d4d16\n","  Stored in directory: /root/.cache/pip/wheels/83/e2/74/46c887b0989a51a7acee0c09551a3ae9d34b939fb4bea404a0\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=685a492766e090a9a0ec50e6bdb673c903ead21f7ab6e3d3359b9da604fbb034\n","  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=629cfe3e6f2ec4becf1077f55c5987142f12488e189bc0950c7ac8df6d283f92\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","Successfully built aitextgen fire future\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, PyYAML, fsspec, aiohttp, torchmetrics, tokenizers, sacremoses, pyDeprecate, huggingface-hub, future, transformers, pytorch-lightning, fire, aitextgen\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 aitextgen-0.5.2 async-timeout-4.0.1 asynctest-0.13.0 fire-0.4.0 frozenlist-1.2.0 fsspec-2021.11.1 future-0.18.2 huggingface-hub-0.2.1 multidict-5.2.0 pyDeprecate-0.3.1 pytorch-lightning-1.5.4 sacremoses-0.0.46 tokenizers-0.10.3 torchmetrics-0.6.0 transformers-4.12.5 yarl-1.7.2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxjsoJ3iQkAB","executionInfo":{"status":"ok","timestamp":1638618459749,"user_tz":-120,"elapsed":855,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"8cd96c86-f4fa-4fe7-8c24-9eafcb8d119f"},"source":["import json\n","\n","api_token = {\"username\":\"courageekoh\",\"key\":\"83bc06bfc6490721d52067847e849603\"}\n","\n","!mkdir .kaggle\n","!mkdir ~/.kaggle\n","\n","with open('/content/kaggle.json', 'w') as file:\n","  json.dump(api_token, file)\n","\n","!cp /content/kaggle.json /root/.kaggle/kaggle.json\n","!chmod 600 /root/.kaggle/kaggle.json"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘.kaggle’: File exists\n","mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9p1iCzmgQj8l","executionInfo":{"status":"ok","timestamp":1638618462743,"user_tz":-120,"elapsed":3000,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"e25ee601-db61-4163-dee5-84ecc7a628aa"},"source":["!pip install kaggle\n","!kaggle --version"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n","Kaggle API 1.5.4\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ynAnrEyWQjgz","executionInfo":{"status":"ok","timestamp":1638618956015,"user_tz":-120,"elapsed":14638,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"322b4464-0b44-4571-c418-fc9036521f43"},"source":["!kaggle datasets download -d courageekoh/code-to-docstring-finetune-encoder-decoder"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading code-to-docstring-finetune-encoder-decoder.zip to /content\n"," 99% 1.56G/1.57G [00:13<00:00, 115MB/s]\n","100% 1.57G/1.57G [00:13<00:00, 125MB/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1q7H13tjTU9P","executionInfo":{"status":"ok","timestamp":1638619018483,"user_tz":-120,"elapsed":17763,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"a0179e14-33c7-4fe7-de6d-885b3fc88851"},"source":["!unzip code-to-docstring-finetune-encoder-decoder.zip -d data "],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  code-to-docstring-finetune-encoder-decoder.zip\n","  inflating: data/encoder_decoder/checkpoint-42000/config.json  \n","  inflating: data/encoder_decoder/checkpoint-42000/optimizer.pt  \n","  inflating: data/encoder_decoder/checkpoint-42000/pytorch_model.bin  \n","  inflating: data/encoder_decoder/checkpoint-42000/rng_state.pth  \n","  inflating: data/encoder_decoder/checkpoint-42000/scaler.pt  \n","  inflating: data/encoder_decoder/checkpoint-42000/scheduler.pt  \n","  inflating: data/encoder_decoder/checkpoint-42000/special_tokens_map.json  \n","  inflating: data/encoder_decoder/checkpoint-42000/tokenizer.json  \n","  inflating: data/encoder_decoder/checkpoint-42000/tokenizer_config.json  \n","  inflating: data/encoder_decoder/checkpoint-42000/trainer_state.json  \n","  inflating: data/encoder_decoder/checkpoint-42000/training_args.bin  \n","  inflating: data/encoder_decoder/runs/Nov29_21-39-19_4276d342c1ee/1638221963.9234145/events.out.tfevents.1638221963.4276d342c1ee.27.1  \n","  inflating: data/encoder_decoder/runs/Nov29_21-39-19_4276d342c1ee/events.out.tfevents.1638221963.4276d342c1ee.27.0  \n"]}]},{"cell_type":"markdown","metadata":{"id":"03-rfRHjQSTB"},"source":["df = pd.read_csv('lichess_elite.csv')"]},{"cell_type":"markdown","metadata":{"id":"HeT4AUpdQSTC"},"source":["df.sample(1_000_000).to_csv('lichess_elite_sampled.csv')"]},{"cell_type":"markdown","metadata":{"id":"8-mr9oivQSTD"},"source":["df"]},{"cell_type":"markdown","metadata":{"id":"Ul52VwW2D-IX"},"source":["## Loading the libraries"]},{"cell_type":"code","metadata":{"id":"IWWLMcr0Yosy","executionInfo":{"status":"ok","timestamp":1638619096052,"user_tz":-120,"elapsed":3156,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["import transformers\n","import pandas as pd\n","\n","#Tokenizer\n","from transformers import RobertaTokenizerFast\n","\n","#Encoder-Decoder Model\n","from transformers import EncoderDecoderModel\n","\n","import numpy as np\n","\n","from nltk.translate import bleu\n","from nltk.translate.bleu_score import SmoothingFunction\n","smoothie = SmoothingFunction().method4\n","\n","\n","from transformers import Seq2SeqTrainer\n","from transformers import Seq2SeqTrainingArguments\n","from dataclasses import dataclass, field\n","from typing import Optional\n","from tqdm.notebook import tqdm\n","\n","import os"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DITcTgiDXHy1","executionInfo":{"status":"ok","timestamp":1638620028065,"user_tz":-120,"elapsed":3114,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"b16edf8c-06e5-419d-8882-7f29254c6663"},"source":["!pip show tokenizers"],"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: tokenizers\n","Version: 0.10.3\n","Summary: Fast and Customizable Tokenizers\n","Home-page: https://github.com/huggingface/tokenizers\n","Author: Anthony MOI\n","Author-email: anthony@huggingface.co\n","License: Apache License 2.0\n","Location: /usr/local/lib/python3.7/dist-packages\n","Requires: \n","Required-by: transformers\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"80cdTzPRrJPg","executionInfo":{"status":"ok","timestamp":1638620190619,"user_tz":-120,"elapsed":17977,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"d10c9a98-bab5-46f2-acc4-7aa2d26334e0"},"source":["from transformers import RobertaTokenizerFast, RobertaForCausalLM, RobertaConfig\n","import torch\n","\n","path = os.path.join(os.getcwd(),\"/content/data/encoder_decoder/checkpoint-42000\")\n","\n","tokenizer = RobertaTokenizerFast.from_pretrained(path)\n","model = EncoderDecoderModel.from_pretrained(path)\n","model.to('cuda')"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stderr","text":["The following encoder weights were not tied to the decoder ['roberta/pooler']\n","The following encoder weights were not tied to the decoder ['roberta/pooler']\n"]},{"output_type":"execute_result","data":{"text/plain":["EncoderDecoderModel(\n","  (encoder): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50000, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (decoder): RobertaForCausalLM(\n","    (roberta): RobertaModel(\n","      (embeddings): RobertaEmbeddings(\n","        (word_embeddings): Embedding(50000, 768, padding_idx=1)\n","        (position_embeddings): Embedding(514, 768, padding_idx=1)\n","        (token_type_embeddings): Embedding(1, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): RobertaEncoder(\n","        (layer): ModuleList(\n","          (0): RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (crossattention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (lm_head): RobertaLMHead(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (decoder): Linear(in_features=768, out_features=50000, bias=True)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"7bzlWXoTV2Un","executionInfo":{"status":"ok","timestamp":1638619771138,"user_tz":-120,"elapsed":414,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"ea563844-29a9-40b9-e944-a754150b32c8"},"source":["path"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/data/encoder_decoder/checkpoint-42000'"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"m5d5Scs2VqgC","executionInfo":{"status":"ok","timestamp":1638619594065,"user_tz":-120,"elapsed":394,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"e01f738e-7f69-45e2-fdc1-65833f973d60"},"source":["path"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/data/encoder_decoder/checkpoint-42000'"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"fJymD7y1QSTI","executionInfo":{"status":"ok","timestamp":1638619587194,"user_tz":-120,"elapsed":417,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["def calc_smooth_bleu(ref, hyp):\n","    return bleu([ref], hyp, smoothing_function=smoothie)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"YZMV-UuhQSTJ","executionInfo":{"status":"ok","timestamp":1638619715332,"user_tz":-120,"elapsed":392,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["data = pd.read_csv('encode_deode_bleu.csv')\n","data['predicted'] = ''\n","data['bleu_score'] = ''"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"xSML1CsvQSTK","executionInfo":{"status":"ok","timestamp":1638619717033,"user_tz":-120,"elapsed":12,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"c563d8c0-129a-4d3a-89dd-b80b843c1b4e"},"source":["data.head()"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>target</th>\n","      <th>predicted</th>\n","      <th>bleu_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>summarize: def write_comment(fh, comment):\\n  ...</td>\n","      <td>Writes a comment to the file in Java propertie...</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>summarize: def register_post_execute(self, fun...</td>\n","      <td>Register a function for calling after code exe...</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>summarize: def frames_to_samples(frames, hop_l...</td>\n","      <td>Converts frame indices to audio sample indices.</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>summarize: def partition(condition, collection...</td>\n","      <td>Partitions a list into two based on a condition.</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>summarize: def _get_axis_mode(self, axis):\\n  ...</td>\n","      <td>will get the axis mode for the current series</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               input  ... bleu_score\n","0  summarize: def write_comment(fh, comment):\\n  ...  ...           \n","1  summarize: def register_post_execute(self, fun...  ...           \n","2  summarize: def frames_to_samples(frames, hop_l...  ...           \n","3  summarize: def partition(condition, collection...  ...           \n","4  summarize: def _get_axis_mode(self, axis):\\n  ...  ...           \n","\n","[5 rows x 4 columns]"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"043OwTWIQSTL","executionInfo":{"status":"ok","timestamp":1638619721122,"user_tz":-120,"elapsed":468,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"a2b87d53-4f58-4b8f-c454-0af63b3ceab8"},"source":["data['input'][0]"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'summarize: def write_comment(fh, comment):\\n  \"\"\"\\n    \\n  \"\"\"\\n  _require_string(comment, \\'comments\\')\\n  fh.write(_escape_comment(comment))\\n  fh.write(b\\'\\\\n\\')'"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["e8b2e0da756147e198e3bccb28076dbd","cdef73fa64d3475d965ac0f6af413e90","0e9df41469ff42f28d0d3b8b400775ff","9c11374248d0495c86fd5caceeb38f66","13aa750da3324bd2bb07e1f5832344bb","563977aaab824bb69e71602dcf27a6c9","a3e5f08e31414b46a0d5b5d596ae4f2e","a7ee517c11684663b1e1fed381753758","a20f670b08844d579dc3c21fe6e570eb","a45c9fee837a4038853d01a60c728113","5186af8394114659a4d37bd2a5ec0ecb"]},"id":"lXGL1UKvQSTM","executionInfo":{"status":"ok","timestamp":1638621786954,"user_tz":-120,"elapsed":1568304,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"5e84fde6-1bf6-4b2e-d988-3fa6ccd6d555"},"source":["for i in tqdm(range(len(data)), total = len(data)):\n","    p = data['input'][i]\n","\n","    input_ids = tokenizer.encode(p, return_tensors='pt').cuda()\n","\n","    sample_outputs = model.generate(\n","        input_ids,\n","        do_sample=True, \n","        max_length=50, \n","        top_k=50, \n","        top_p=0.95, \n","        num_return_sequences=3\n","    )\n","\n","    a = []\n","\n","    for idx, sample_output in enumerate(sample_outputs):\n","        a.append(tokenizer.decode(sample_output, skip_special_tokens=True))\n","\n","    ref = [' '.join(data['target'][i].split())]\n","    pred = [[' '.join(j.split())] for j in a]\n","\n","    bleu_scores = []\n","\n","    for k in pred:\n","      score = calc_smooth_bleu(ref[0], k[0])*100\n","      bleu_scores.append(score)\n","\n","    data['predicted'][i] = pred[np.argmax(bleu_scores)][0]\n","    data['bleu_score'][i] = max(bleu_scores)"],"execution_count":48,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8b2e0da756147e198e3bccb28076dbd","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1001 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py:2142: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  next_indices = next_tokens // vocab_size\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"nKhSANLBeGrE","executionInfo":{"status":"ok","timestamp":1638621806135,"user_tz":-120,"elapsed":433,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"aee5e00f-f115-4b29-be65-114a8a953723"},"source":["data"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>target</th>\n","      <th>predicted</th>\n","      <th>bleu_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>summarize: def write_comment(fh, comment):\\n  ...</td>\n","      <td>Writes a comment to the file in Java propertie...</td>\n","      <td>s to and the a an of for from in_.].]])))) ) p...</td>\n","      <td>12.3961</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>summarize: def register_post_execute(self, fun...</td>\n","      <td>Register a function for calling after code exe...</td>\n","      <td>=_ a. thes to an of with licies None get this,...</td>\n","      <td>9.703</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>summarize: def frames_to_samples(frames, hop_l...</td>\n","      <td>Converts frame indices to audio sample indices.</td>\n","      <td>=_ a. thesname to for of in all default Retrie...</td>\n","      <td>7.61272</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>summarize: def partition(condition, collection...</td>\n","      <td>Partitions a list into two based on a condition.</td>\n","      <td>=_ a. the to allsname for in not( ( this an of...</td>\n","      <td>13.8349</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>summarize: def _get_axis_mode(self, axis):\\n  ...</td>\n","      <td>will get the axis mode for the current series</td>\n","      <td>s and for the a an of to from in_.().].'].').'...</td>\n","      <td>10.9254</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>summarize: def url_value_preprocessor(self, f)...</td>\n","      <td>Registers a function as URL value preprocessor...</td>\n","      <td>s to a the an of for and or from in_.().(),())...</td>\n","      <td>19.8944</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>summarize: async def parse_vn_results(soup):\\n...</td>\n","      <td>Parse Visual Novel search pages.</td>\n","      <td>='=_ a.s thename to for of anRetrieve(('(_ ( a...</td>\n","      <td>9.46519</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>summarize: def generate(secret, age, **payload...</td>\n","      <td>Generate a one-time jwt with an age in seconds</td>\n","      <td>s the a an of to for and or from in_.().(),())...</td>\n","      <td>9.62507</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>summarize: def char_tokens_to_char_offsets(si_...</td>\n","      <td>Convert character ``Offset``s to character ran...</td>\n","      <td>=_ a. the to allsname and ( of in,' -: not( se...</td>\n","      <td>4.74968</td>\n","    </tr>\n","    <tr>\n","      <th>1000</th>\n","      <td>summarize: def driver_for_path(path, drivers=N...</td>\n","      <td>Returns the gdal.Driver for a path or None bas...</td>\n","      <td>((_ ( thename a and to alls _ for, of'\"\" Runs ...</td>\n","      <td>16.2819</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1001 rows × 4 columns</p>\n","</div>"],"text/plain":["                                                  input  ... bleu_score\n","0     summarize: def write_comment(fh, comment):\\n  ...  ...    12.3961\n","1     summarize: def register_post_execute(self, fun...  ...      9.703\n","2     summarize: def frames_to_samples(frames, hop_l...  ...    7.61272\n","3     summarize: def partition(condition, collection...  ...    13.8349\n","4     summarize: def _get_axis_mode(self, axis):\\n  ...  ...    10.9254\n","...                                                 ...  ...        ...\n","996   summarize: def url_value_preprocessor(self, f)...  ...    19.8944\n","997   summarize: async def parse_vn_results(soup):\\n...  ...    9.46519\n","998   summarize: def generate(secret, age, **payload...  ...    9.62507\n","999   summarize: def char_tokens_to_char_offsets(si_...  ...    4.74968\n","1000  summarize: def driver_for_path(path, drivers=N...  ...    16.2819\n","\n","[1001 rows x 4 columns]"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IiVStrlMQSTO","executionInfo":{"status":"ok","timestamp":1638621801861,"user_tz":-120,"elapsed":449,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"9bd57daa-8f58-4640-d035-82099ed656bb"},"source":["!nvidia-smi"],"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Dec  4 12:43:23 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P0    35W / 250W |   3437MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"jiKxv1NMQSTO","executionInfo":{"status":"ok","timestamp":1638621836567,"user_tz":-120,"elapsed":413,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["data.to_csv('code_to_text_enc_dec.csv', index = False)"],"execution_count":51,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"55LDbKHEQSTP"},"source":["## Random Test Code"]},{"cell_type":"code","metadata":{"id":"12_xysPIQSTP"},"source":["p = 'summarize: def _enable_autopx(self):\\n        \"\"\"\\n        \"\"\"\\n        # override run_cell\\n        self._original_run_cell = self.shell.run_cell\\n        self.shell.run_cell = self.pxrun_cell\\n\\n        self._autopx = True\\n        print \"%autopx enabled\"'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l1R-V9WMQSTQ"},"source":["# encode context the generation is conditioned on\n","input_ids = tokenizer.encode(p, return_tensors='pt') #.to('cuda')\n","\n","# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n","sample_outputs = model.generate(\n","    input_ids,\n","    do_sample=True, \n","    max_length=50, \n","    top_k=50, \n","    top_p=0.95, \n","    num_return_sequences=3\n",")\n","\n","pred = []\n","\n","\n","\n","print(\"Output:\\n\" + 100 * '-')\n","for i, sample_output in enumerate(sample_outputs):\n","    pred.append([tokenizer.decode(sample_output, skip_special_tokens=True)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dZKWOvCJQSTR"},"source":["pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4MfdUW36QSTS"},"source":["sample_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMRYwOlmiDqw"},"source":[""],"execution_count":null,"outputs":[]}]}