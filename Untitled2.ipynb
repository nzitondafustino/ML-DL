{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"colab":{"name":"Untitled2.ipynb","provenance":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7fdc02b7","executionInfo":{"status":"ok","timestamp":1633078573880,"user_tz":-120,"elapsed":2169,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import numpy as np\n","import matplotlib.pyplot as plt"],"id":"7fdc02b7","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2e7d9643","executionInfo":{"status":"ok","timestamp":1633078999948,"user_tz":-120,"elapsed":105973,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"0211abb7-bd53-4cd6-9260-ecd86ee097bf"},"source":["import os\n","kaggle_data={\"username\":\"kleber0\",\"key\":\"31c7efab560bf0ae89adce7fa28372ed\"}\n","os.environ['KAGGLE_USERNAME']=kaggle_data[\"username\"]\n","os.environ['KAGGLE_KEY']=kaggle_data[\"key\"]\n","import kaggle\n","!kaggle competitions download -c idl-fall2021-hw1p2\n","!unzip /content/dev.npy.zip\n","!unzip /content/dev_labels.npy.zip\n","!unzip /content/train.npy.zip\n","!unzip /content/train_labels.npy.zip\n","!unzip /content/test.npy.zip"],"id":"2e7d9643","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n","Downloading dev.npy.zip to /content\n"," 97% 239M/246M [00:02<00:00, 136MB/s]\n","100% 246M/246M [00:02<00:00, 126MB/s]\n","Downloading dev_labels.npy.zip to /content\n","  0% 0.00/617k [00:00<?, ?B/s]\n","100% 617k/617k [00:00<00:00, 197MB/s]\n","Downloading train.npy.zip to /content\n","100% 1.92G/1.92G [00:14<00:00, 158MB/s]\n","100% 1.92G/1.92G [00:14<00:00, 144MB/s]\n","Downloading sample.csv.zip to /content\n","100% 4.03M/4.03M [00:00<00:00, 27.0MB/s]\n","\n","Downloading test.npy.zip to /content\n"," 99% 239M/241M [00:02<00:00, 79.6MB/s]\n","100% 241M/241M [00:02<00:00, 111MB/s] \n","Downloading train_labels.npy.zip to /content\n","  0% 0.00/5.16M [00:00<?, ?B/s]\n","100% 5.16M/5.16M [00:00<00:00, 171MB/s]\n","Archive:  /content/dev.npy.zip\n","  inflating: dev.npy                 \n","Archive:  /content/dev_labels.npy.zip\n","  inflating: dev_labels.npy          \n","Archive:  /content/train.npy.zip\n","  inflating: train.npy               \n","Archive:  /content/train_labels.npy.zip\n","  inflating: train_labels.npy        \n","Archive:  /content/test.npy.zip\n","  inflating: test.npy                \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ehyhnipEY59","executionInfo":{"status":"ok","timestamp":1633079529726,"user_tz":-120,"elapsed":459,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"d98b33b9-520e-4e52-c11c-f2eff1358730"},"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"id":"5ehyhnipEY59","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}]},{"cell_type":"code","metadata":{"id":"ab43bc01","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633079532307,"user_tz":-120,"elapsed":466,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"64de4160-5841-4676-a94b-a5b4a05be581"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"id":"ab43bc01","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","metadata":{"id":"793cc93e","executionInfo":{"status":"ok","timestamp":1633079630474,"user_tz":-120,"elapsed":95047,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["train_data = np.load('/content/train.npy', allow_pickle = True)\n","train_labels = np.load('/content/train_labels.npy', allow_pickle = True)\n","val_data = np.load('/content/dev.npy', allow_pickle = True)\n","val_labels = np.load('/content/dev_labels.npy', allow_pickle = True)\n","test_data = np.load('/content/test.npy', allow_pickle = True)"],"id":"793cc93e","execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fb72bde","executionInfo":{"status":"ok","timestamp":1633079636457,"user_tz":-120,"elapsed":503,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["output_size = 71\n","hidden_size = 2048\n","learning_rate = 0.001\n","epochs = 20\n","batch_size = 32\n","context = 20\n","pad_val = 20\n","input_size = (1 + 2*context)*40"],"id":"8fb72bde","execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"54be0b06","executionInfo":{"status":"ok","timestamp":1633079640785,"user_tz":-120,"elapsed":492,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["class myDataset(Dataset):\n","    \n","    def __init__(self, X, Y=None, pad_val=5, context=5, is_test = False):\n","        \n","        ### Add data and label to self (1-2 lines)\n","        self.X = X\n","        self.Y = Y\n","        self.is_test = is_test\n","        ### Define data index mapping (4-6 lines)\n","        index_map_x = []\n","        for i, x in enumerate(X):\n","            for j, xx in enumerate(x):\n","                index_pair_x = (i, j)\n","                index_map_x.append(index_pair_x)\n","                \n","        ### Define label index mapping (4-6 lines)\n","        if(not is_test):\n","            index_map_y = []\n","            for i, y in enumerate(Y):\n","                for j, yy in enumerate(y):\n","                    index_pair_y = (i, j)\n","                    index_map_y.append(index_pair_y)\n","\n","            ### Assert the data index mapping and label index mapping are the same (1 line)\n","\n","            assert(set(index_map_x) == set(index_map_y))\n","\n","        ### Assign data index mapping to self (1 line)\n","        self.index_map_X = index_map_x\n","        \n","        ### Add length to self (1 line)\n","        self.length = len(self.index_map_X)\n","        \n","        ### Add context and offset to self (1-2 line)\n","        self.pad_val = pad_val\n","        self.context = context\n","        \n","        ### Zero pad data as-needed for context size = 1 (1-2 lines)\n","        for i, x in enumerate(self.X):\n","            self.X[i] = np.pad(x,((pad_val, pad_val), (0, 0)),'constant',constant_values=0)\n","        \n","    def __len__(self):\n","        \n","        ### Return length (1 line)\n","        return self.length\n","    \n","    def __getitem__(self, index):\n","        \n","        ### Get index pair from index map (1-2 lines)\n","        i, j= self.index_map_X[index]\n","        \n","        ### Calculate starting timestep using offset and context (1 line)\n","        start_j = j + self.pad_val - self.context\n","        \n","        ## Calculate ending timestep using offset and context (1 line)\n","        end_j = j + self.pad_val + self.context + 1\n","        \n","        ### Get data at index pair with context (1 line)\n","        x = self.X[i][start_j:end_j,:]\n","        \n","        ### Get label at index pair (1 line)\n","        if(not self.is_test):\n","            y = self.Y[i][j]\n","            ### Return data at index pair with context and label at index pair (1 line)\n","            return x, y\n","        else:\n","            return x\n","    \n","    def collate_fn(batch):\n","        \n","        batch_x = [x for x,y in batch]\n","        batch_x = torch.as_tensor(batch_x)\n","        if(not self.is_test):\n","            batch_y = [y for x,y in batch]        \n","            batch_y = torch.as_tensor(batch_y)\n","            return batch_x, batch_y\n","        else:\n","            return batch_x"],"id":"54be0b06","execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"c9204030","executionInfo":{"status":"ok","timestamp":1633079642755,"user_tz":-120,"elapsed":5,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["class Model(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super().__init__()\n","        self.l1 = nn.Linear(input_size, hidden_size,device=device)\n","        self.l2 = nn.Linear(hidden_size,int(hidden_size/2),device=device)\n","        self.l3 = nn.Linear(int(hidden_size/2),int(hidden_size/4),device=device)\n","        self.l4 = nn.Linear(int(hidden_size/4),output_size,device=device)\n","    \n","    def forward(self,x):\n","        out = self.l1(x)\n","        out = F.relu(out)\n","        out = self.l2(out)\n","        out = F.relu(out)\n","        out = self.l3(out)\n","        out = F.relu(out)\n","        out = self.l4(out)\n","        return out"],"id":"c9204030","execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"5686647e"},"source":["# torch.save({\n","#     'epoch':epoch,\n","#     'model_state_dict': model.state_dict(),\n","#     'optimizer_state_dict':optimizer.state_dict(),\n","#     'loss':loss\n","# },PATH)"],"id":"5686647e","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"33df8d50"},"source":["# checkpoint = {\n","#     \"epoch\":20,\n","#     \"model_state\":model.state_dict(),\n","#     \"optim_state\":optimizer.state_dict(),\n","#     \"loss\":loss\n","# }\n","# torch.save(checkpoint,\"checkpoint.pth\")"],"id":"33df8d50","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c4d92729","executionInfo":{"status":"ok","timestamp":1633079661054,"user_tz":-120,"elapsed":518,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}}},"source":["def init_weights(model):\n","    if isinstance(model, nn.Linear):\n","        torch.nn.init.xavier_uniform(model.weight)\n","        model.bias.data.fill_(0.01)"],"id":"c4d92729","execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8975a77a","executionInfo":{"status":"ok","timestamp":1633079670271,"user_tz":-120,"elapsed":6873,"user":{"displayName":"Faustin Nzitonda","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03681400882233025560"}},"outputId":"c333920e-20ee-44b3-c5b9-93cfe9a2dffe"},"source":["criterion = nn.CrossEntropyLoss().to(device)\n","model = Model(input_size,hidden_size,output_size)\n","model.apply(init_weights)\n","model.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n","# checkpoint = torch.load(PATH)\n","# model.load_state_dict(checkpoint['model_state_dict'])\n","# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","# epoch = checkpoint['epoch']\n","# loss = checkpoint['loss']\n"],"id":"8975a77a","execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}]},{"cell_type":"code","metadata":{"id":"37d21890"},"source":["train_dataset = myDataset(train_data, train_labels, pad_val, context)\n","val_dataset = myDataset(val_data, val_labels, pad_val, context)\n","train_loader = DataLoader(dataset = train_dataset ,batch_size = batch_size, shuffle = True)\n","val_loader = DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle = False)"],"id":"37d21890","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"75fe9804"},"source":["n_total_steps = len(train_loader)\n","val_loss_min = np.Inf\n","for epoch in range(epochs):\n","    running_loss = 0\n","    last_loss = 0\n","    model.train()\n","    for i, (data, labels) in enumerate(train_loader):\n","#         print(data.shape)\n","        data = data.reshape(batch_size,-1).to(device)\n","#         print(data.dtype)\n","#         print(data.shape)\n","        labels = labels.to(device)\n","#         print(labels.shape)\n","        output = model(data.float())\n","        loss = criterion(output, labels.long())\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","        running_loss = running_loss/(i+1)\n","    running_val_loss = 0\n","    model.eval()\n","    for j, (val_data,val_labels) in enumerate(val_loader):\n","        val_data = val_data.reshape(batch_size,-1).to(device)\n","        val_labels = val_labels.to(device) \n","        val_output = model(val_data.float())\n","        val_loss = criterion(val_output, val_labels.long())\n","        running_val_loss += val_loss\n","        running_val_loss = running_val_loss/(j+1)\n","        \n","    if (i+1) % 2000 == 1999:\n","       \n","        print(f'epoch {epoch+1} /{num_epochs}, step {i+1}/{n_total_steps}, train_loss = {running_loss}, val_loss = {running_val_loss}')\n","        running_loss = 0\n","        running_val_loss = 0\n","    checkpoint = {\n","        \"epoch\":epoch+1,\n","        \"model_state\":model.state_dict(),\n","        \"optim_state\":optimizer.state_dict(),\n","        \"val_loss\":loss\n","    }\n","    if running_val_loss < val_loss_min:\n","        val_loss_min = val_loss\n","        torch.save(checkpoint,PATH)\n","        "],"id":"75fe9804","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0d39005a"},"source":["test_dataset = myDataset(test_data,None,pad_val,context,is_test=True)\n","test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)"],"id":"0d39005a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ac2261e9"},"source":["pred = []\n","for k,(test_data) in enumerate(test_dataloader):\n","    with torch.no_grad():\n","        test_data = val_data.reshape(batch_size,-1).to(device)\n","        test_output = model(test_data.float())\n","        pred.append(torch.argmax(test_output, dim=1))"],"id":"ac2261e9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"45206356"},"source":[""],"id":"45206356","execution_count":null,"outputs":[]}]}